{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-17T07:10:45.025277Z",
     "iopub.status.busy": "2023-11-17T07:10:45.024982Z",
     "iopub.status.idle": "2023-11-17T07:10:45.050373Z",
     "shell.execute_reply": "2023-11-17T07:10:45.049541Z",
     "shell.execute_reply.started": "2023-11-17T07:10:45.025229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['archive.zip', 'skin-cancer-mnist-ham10000']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"/u/student/2020/cs20btech11046/resnet/input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0942758b1f1d0ca25e3afe13d080a535b97af4d0",
    "execution": {
     "iopub.execute_input": "2023-11-17T07:10:45.051585Z",
     "iopub.status.busy": "2023-11-17T07:10:45.051324Z",
     "iopub.status.idle": "2023-11-17T07:10:45.138573Z",
     "shell.execute_reply": "2023-11-17T07:10:45.137820Z",
     "shell.execute_reply.started": "2023-11-17T07:10:45.051546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('/u/student/2020/cs20btech11046/resnet/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-11-17T07:10:45.144764Z",
     "iopub.status.busy": "2023-11-17T07:10:45.142650Z"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import isfile\n",
    "from PIL import Image as pil_image\n",
    "df['num_images'] = df.groupby('lesion_id')[\"image_id\"].transform(\"count\")\n",
    "\n",
    "classes = df['dx'].unique()\n",
    "labeldict = {}\n",
    "for num, name in enumerate(classes):\n",
    "    labeldict[name] = num\n",
    "df['dx_id'] = df['dx'].map(lambda x: labeldict[x])\n",
    "\n",
    "\n",
    "def expand_path(p):\n",
    "    if isfile('../input/skin-cancer-mnist-ham10000/ham10000_images_part_1/' + p + '.jpg'): return '../input/skin-cancer-mnist-ham10000/ham10000_images_part_1/' + p + '.jpg'\n",
    "    if isfile('../input/skin-cancer-mnist-ham10000/ham10000_images_part_2/' + p + '.jpg'): return '../input/skin-cancer-mnist-ham10000/ham10000_images_part_2/' + p + '.jpg'\n",
    "    return p \n",
    "df['image_path'] = df['image_id']\n",
    "df['image_path'] = df['image_path'].apply(expand_path)\n",
    "\n",
    "\n",
    "df['images'] = df['image_path'].map(lambda x: np.asarray(pil_image.open(x).resize((150,112))))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "355820d0b11562b8d41525d50bddc145173b1f69"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_single = df[df['num_images'] == 1]\n",
    "trainset1, testset = train_test_split(df_single, test_size=0.2,random_state = 80)\n",
    "trainset2, validationset = train_test_split(trainset1, test_size=0.2,random_state = 600)\n",
    "trainset3 = df[df['num_images'] != 1]\n",
    "frames = [trainset2, trainset3]\n",
    "trainset = pd.concat(frames)\n",
    "def prepareimages(images):\n",
    "    # images is a list of images\n",
    "    images = np.asarray(images).astype(np.float64)\n",
    "    images = images[:, :, :, ::-1]\n",
    "    m0 = np.mean(images[:, :, :, 0])\n",
    "    m1 = np.mean(images[:, :, :, 1])\n",
    "    m2 = np.mean(images[:, :, :, 2])\n",
    "    images[:, :, :, 0] -= m0\n",
    "    images[:, :, :, 1] -= m1\n",
    "    images[:, :, :, 2] -= m2\n",
    "    return images\n",
    "trainimages = prepareimages(list(trainset['images']))\n",
    "testimages = prepareimages(list(testset['images']))\n",
    "validationimages = prepareimages(list(validationset['images']))\n",
    "trainlabels = np.asarray(trainset['dx_id'])\n",
    "testlabels = np.asarray(testset['dx_id'])\n",
    "validationlabels = np.asarray(validationset['dx_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b29b5a001c6cf2d40cd3098269028d65a55ad4e1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(trainlabels,bins = 7,density = True)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(validationlabels,bins = 7,density= True)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(testlabels,bins = 7,density= True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94cb00633c4fce5e9e8e9f10168112cb694e0be0"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "trainimages = trainimages.reshape(trainimages.shape[0], *(112, 150, 3))\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1)  # randomly shift images vertically\n",
    "#x = imageLoader(trainset,batch_size)\n",
    "data_gen.fit(trainimages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9901b04d365e91b7fdfce419f77d488e6fa44079"
   },
   "outputs": [],
   "source": [
    "#from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "num_labels = 7\n",
    "\n",
    "base_model = ResNet50(include_top=False, input_shape=(112, 150, 3),pooling = 'avg', weights = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_labels, activation = 'softmax',kernel_regularizer=regularizers.l2(0.02)))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in base_model.layers[-22:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "#model.add(ResNet50(include_top = False, pooling = 'max', weights = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da90ad4154783b13e6d8220ffbb6701652bfdf8a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import Adam\n",
    "optimizer = Adam (lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "model.compile(optimizer = optimizer , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffa99865f98239a767fc1f3603686b1c9fad3b83"
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "import keras\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "class CustomModelCheckPoint(keras.callbacks.Callback):\n",
    "    def __init__(self,**kargs):\n",
    "        super(CustomModelCheckPoint,self).__init__(**kargs)\n",
    "        self.epoch_accuracy = {} # loss at given epoch\n",
    "        self.epoch_loss = {} # accuracy at given epoch\n",
    "        def on_epoch_begin(self,epoch, logs={}):\n",
    "            # Things done on beginning of epoch. \n",
    "            return\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            # things done on end of the epoch\n",
    "            self.epoch_accuracy[epoch] = logs.get(\"acc\")\n",
    "            self.epoch_loss[epoch] = logs.get(\"loss\")\n",
    "            self.model.save_weights(\"../output/resnet50/name-of-model-%d.h5\" %epoch)\n",
    "            \n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 4)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n",
    "            \n",
    "epochs = 30 \n",
    "batch_size = 20\n",
    "trainhistory = model.fit_generator(data_gen.flow(trainimages,trainlabels, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (validationimages,validationlabels),\n",
    "                              verbose = 1, steps_per_epoch=trainimages.shape[0] // batch_size,\n",
    "                                       callbacks=[cb_checkpointer, cb_early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca871a8020079ad0d2ccf849843ada3204e0cbfd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = trainhistory.history['acc']\n",
    "val_acc = trainhistory.history['val_acc']\n",
    "loss = trainhistory.history['loss']\n",
    "val_loss = trainhistory.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, '', label='Training loss')\n",
    "plt.plot(epochs, val_loss, '', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, '', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, '', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1e365fc56e551ec9171f06ce57910077c0b2de8"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"../working/best.hdf5\")\n",
    "test_loss, test_acc = model.evaluate(testimages, testlabels, verbose=1)\n",
    "print(\"test_accuracy = %f  ;  test_loss = %f\" % (test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b0093bc08c6b4c94a29bdb7ae0030b83416863b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "train_pred = model.predict(trainimages)\n",
    "train_pred_classes = np.argmax(train_pred,axis = 1)\n",
    "test_pred = model.predict(testimages)\n",
    "# Convert predictions classes to one hot vectors \n",
    "test_pred_classes = np.argmax(test_pred,axis = 1) \n",
    "\n",
    "confusionmatrix = confusion_matrix(testlabels, test_pred_classes)\n",
    "confusionmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "100cef840daf94ce53d57e9cc39a673e7a7437e9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "labels = labeldict.keys()\n",
    "# Generate a classification report\n",
    "trainreport = classification_report(trainlabels, train_pred_classes, target_names=list(labels))\n",
    "testreport = classification_report(testlabels, test_pred_classes, target_names=list(labels))\n",
    "\n",
    "print(trainreport)\n",
    "print(testreport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf12165b585cda61dfcd190c9b149d0e00e024fc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 121688,
     "sourceId": 293272,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 20477,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
